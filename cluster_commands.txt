######################################################################
# main authors: Mats Simmermacher, Andres Moreno Carrascosa          #
# and Stefan Behnle                                                  # 
######################################################################

----------------------------------------------------------------------
Commands for Computing on EDDIE
----------------------------------------------------------------------

- jobs can be submitted with
qsub <script.sh>,
where script.sh is a submission script

- submitted or running jobs can be monitored with
qstat;
this also displays the IDs of the jobs

- submitted or running jobs can be killed with
qdel <job ID>,
where the job ID can be found via qstat

Please find your own sensible structure for either different job schedulers that
is understandable for both people in TÃ¼bingen and Edinburgh.

============================================================================
=               BASIC CONSIDERATIONS WHEN YOU FIRST ENTER A CLUSTER      =     
============================================================================

- Before running jobs in any cluster, please bear in mind LOGIN NODES are not RUNNING NODES
- Knowing the number of cores and nodes in your cluster is important before submitting your jobs
- The time limit you put in your scripts will determine your position in the queue, do not put 24h to run H2
- Sometimes you will realize a job you just submitted has some error. It is a good practice to kill it before starting a new one. Having a list with your PID's also helps in that task if your user is shared
- Also be careful with the memory assignated to each job, an useful practice would be to read the cluster documentation before hand
- In case some information is not in your university webpage, general instructions can be found in the webpages related to your specific queue system
- If el barrilero is on your group, be careful, he is muuuuuuy estupido
- If you use EMACS, please leave science or consider a quick change to vi
- Before running your brand new code in the cluster, please test it on your local machine (not in the login node) 
- Remember to change the libraries for every run, if you do not source Tensorflow in your submitting script, you will not be able to use it later.  
MUCHAS!!!

==============================================================================
==                    THE  S L U R M  QUEUEING SYSTEM                       ==
==============================================================================

The SLURM workload manager (https://www.schedmd.com/) is a free and open-source queueing system.

The general documentation and tutorials are available from https://slurm.schedmd.com/
For a quick overview see https://slurm.schedmd.com/quickstart.html

The most important commands are

* sbatch <name_of_job_script>

  submits the job defined in <name_of_job_script> to the queue


* squeue
  
  list the jobs in the queue


* scancel <jobid>

    deletes the job specified by <jobid>


The job script has the following structure:



